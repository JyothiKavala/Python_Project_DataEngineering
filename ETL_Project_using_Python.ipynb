{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0903c2d",
   "metadata": {},
   "source": [
    "***Project Scenario:***\n",
    "\n",
    "You have been hired as a data engineer by research organization. Your boss has asked you to create a code that can be used to compile the list of the top 10 largest banks in the world ranked by market capitalization in billion USD. Further, the data needs to be transformed and stored in GBP, EUR and INR as well, in accordance with the exchange rate information that has been made available to you as a CSV file. The processed information table is to be saved locally in a CSV format and as a database table.\n",
    "\n",
    "Your job is to create an automated system to generate this information so that the same can be executed in every financial quarter to prepare the report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a82fcf",
   "metadata": {},
   "source": [
    "**Task 1:**\n",
    "\n",
    "Write a function log_progress() to log the progress of the code at different stages in a file code_log.txt. Use the list of log points provided to create log entries as every stage of the code.\n",
    "\n",
    "**Task 2:**\n",
    "\n",
    "Extract the tabular information from the given URL under the heading 'By market capitalization' and save it to a dataframe.\n",
    "a. Inspect the webpage and identify the position and pattern of the tabular information in the HTML code\n",
    "b. Write the code for a function extract() to perform the required data extraction.\n",
    "c. Execute a function call to extract() to verify the output.\n",
    "\n",
    "**Task 3:**\n",
    "\n",
    "Transform the dataframe by adding columns for Market Capitalization in GBP, EUR and INR, rounded to 2 decimal places, based on the exchange rate information shared as a CSV file.\n",
    "a. Write the code for a function transform() to perform the said task.\n",
    "b. Execute a function call to transform() and verify the output.\n",
    "\n",
    "**Task 4:**\n",
    "\n",
    "Load the transformed dataframe to an output CSV file. Write a function load_to_csv(), execute a function call and verify the output.\n",
    "\n",
    "**Task 5:**\n",
    "\n",
    "Load the transformed dataframe to an SQL database server as a table. Write a function load_to_db(), execute a function call and verify the output.\n",
    "\n",
    "**Task 6:**\n",
    "\n",
    "Run queries on the database table. Write a function load_to_db(), execute a given set of queries and verify the output.\n",
    "\n",
    "**Task 7:**\n",
    "\n",
    "Verify that the log entries have been completed at all stages by checking the contents of the file code_log.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6ca4ac",
   "metadata": {},
   "source": [
    "**Preliminaries:**\n",
    "\n",
    "Installing libraries:\n",
    "\n",
    "python3.11 -m pip install pandas\n",
    "\n",
    "python3.11 -m pip install bs4\n",
    "\n",
    "python3.11 -m pip install numpy\n",
    "\n",
    "Webpage: https://web.archive.org/web/20230908091635%20/https://en.wikipedia.org/wiki/List_of_largest_banks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93582595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef2345ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "\n",
    "table_attribs = [\"Name\", \"MC_USD_Billion\"]\n",
    "output_path = 'C:/Users/jyoth/Downloads/Python_ETL_Project/Largest_banks_data.csv'\n",
    "server_name = 'JYOTHI\\SQLEXPRESS'\n",
    "db_name = 'Banks.db'\n",
    "table_name = 'Largest_banks'\n",
    "csv_path= 'C:/Users/jyoth/Downloads/Python_ETL_Project/exchange_rate.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e676cba",
   "metadata": {},
   "source": [
    "**Task 1: Logging function**\n",
    "\n",
    "The function to log the progress of the code, log_progress(). The function accepts the message to be logged and enters it to a text file code_log.txt\n",
    "\n",
    "Each log entry must happen in the next line in the text file.\n",
    "\n",
    "Correct log entries must be associated with each of the executed function calls. Use the following table to note the logging message at the end of each function call that follows.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bdc885",
   "metadata": {},
   "source": [
    "\n",
    "| **Task**                        | **Log message on completion**                                      |\n",
    "|---------------------------------|--------------------------------------------------------------------|\n",
    "| `Declaring known values`        | `Preliminaries complete. Initiating ETL process`                  |\n",
    "| `Call extract() function`       | `Data extraction complete. Initiating Transformation process`      |\n",
    "| `Call transform() function`     | `Data transformation complete. Initiating Loading process`        |\n",
    "| `Call load_to_csv()`            | `Data saved to CSV file`                                          |\n",
    "| `Initiate SQLite3 connection`   | `SQL Connection initiated`                                        |\n",
    "| `Call load_to_db()`             | `Data loaded to Database as a table, Executing queries`           |\n",
    "| `Call run_query()`              | `Process Complete`                                                |\n",
    "| `Close SQLite3 connection`      | `Server Connection closed`                                        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04b83285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log progress\n",
    "def log_progress(message):\n",
    "    '''Logs a given message with a timestamp'''\n",
    "    timestamp_format = '%Y-%m-%d %H:%M:%S' \n",
    "    now = datetime.now()  \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(\"C:/Users/jyoth/Downloads/Python_ETL_Project/code_log.txt\", \"a\") as f: \n",
    "        f.write(timestamp + ' : ' + message + '\\n')\n",
    "        \n",
    "log_progress('Preliminaries complete. Initiating ETL process')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fece2d4",
   "metadata": {},
   "source": [
    "**Task 2 : Extraction of data**\n",
    "\n",
    "Analyze the webpage on the given URL:\n",
    "\n",
    "\n",
    "URL= https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks\n",
    "\n",
    "Identify the position of the required table under the heading By market capitalization. Write the function extract() to retrieve the information of the table to a Pandas data frame.\n",
    "\n",
    "Note: Remember to remove the last character from the Market Cap column contents, like, '\\n', and typecast the value to float format.\n",
    "\n",
    "Write a function call for extract() and print the returning data frame.\n",
    "\n",
    "Make the relevant log entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78b97a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Name MC_USD_Billion\n",
      "0                           JPMorgan Chase         432.92\n",
      "1                          Bank of America         231.52\n",
      "2  Industrial and Commercial Bank of China         194.56\n",
      "3               Agricultural Bank of China         160.68\n",
      "4                                HDFC Bank         157.91\n",
      "5                              Wells Fargo         155.87\n",
      "6                        HSBC Holdings PLC         148.90\n",
      "7                           Morgan Stanley         140.83\n",
      "8                  China Construction Bank         139.82\n",
      "9                            Bank of China         136.81\n"
     ]
    }
   ],
   "source": [
    "# Extract function\n",
    "def extract(url, table_attribs):\n",
    "    '''Extracts the first table from Wikipedia'''\n",
    "    page = requests.get(url).text\n",
    "    data = BeautifulSoup(page, 'html.parser')\n",
    "    df = pd.DataFrame(columns=table_attribs)\n",
    "    \n",
    "    tables = data.find_all('tbody')  # Locate all table bodies\n",
    "    if len(tables) == 0:\n",
    "        log_progress(\"Error: No tables found on the page.\")\n",
    "        return None\n",
    "    \n",
    "    rows = tables[0].find_all('tr')  # First table (index 0)\n",
    "    for row in rows:\n",
    "        col = row.find_all('td')\n",
    "        if len(col) >= 3:  # Ensure we have enough columns\n",
    "            name = col[1].get_text(strip=True)  # Extract bank name from the correct column\n",
    "            mc_usd_billion = col[2].get_text(strip=True)  # Extract market cap from the correct column\n",
    "            df = pd.concat([df, pd.DataFrame([[name, mc_usd_billion]], columns=table_attribs)], ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Extract data and print results\n",
    "df = extract(url, table_attribs)\n",
    "print(df)\n",
    "log_progress('Data extraction complete. Initiating Transformation process')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31995e7b",
   "metadata": {},
   "source": [
    "**Task 3 : Transformation of data**\n",
    "\n",
    "The Transform function needs to perform the following tasks:\n",
    "\n",
    "Read the exchange rate CSV file and convert the contents to a dictionary so that the contents of the first columns are the keys to the dictionary and the contents of the second column are the corresponding values.\n",
    "\n",
    "Add 3 different columns to the dataframe,  MC_GBP_Billion, MC_EUR_Billion and MC_INR_Billion, each containing the content of MC_USD_Billion scaled by the corresponding exchange rate factor. Round the resulting data to 2 decimal places.\n",
    "\n",
    "Write the function call for transform() and print the contents of the returning data frame. Comment out all previous print statements.\n",
    "\n",
    "Make the relevant log entry and execute the code.\n",
    "\n",
    "***Print the contents of df['MC_EUR_Billion'][4], which is the market capitalization of the 5th largest bank in billion EUR.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb52c73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
      "0                           JPMorgan Chase          432.92          346.34   \n",
      "1                          Bank of America          231.52          185.22   \n",
      "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
      "3               Agricultural Bank of China          160.68          128.54   \n",
      "4                                HDFC Bank          157.91          126.33   \n",
      "5                              Wells Fargo          155.87          124.70   \n",
      "6                        HSBC Holdings PLC          148.90          119.12   \n",
      "7                           Morgan Stanley          140.83          112.66   \n",
      "8                  China Construction Bank          139.82          111.86   \n",
      "9                            Bank of China          136.81          109.45   \n",
      "\n",
      "   MC_EUR_Billion  MC_INR_Billion  \n",
      "0          402.62        35910.71  \n",
      "1          215.31        19204.58  \n",
      "2          180.94        16138.75  \n",
      "3          149.43        13328.41  \n",
      "4          146.86        13098.63  \n",
      "5          144.96        12929.42  \n",
      "6          138.48        12351.26  \n",
      "7          130.97        11681.85  \n",
      "8          130.03        11598.07  \n",
      "9          127.23        11348.39  \n",
      "146.86\n"
     ]
    }
   ],
   "source": [
    "def transform(df, csv_path):\n",
    "    ''' This function accesses the CSV file for exchange rate\n",
    "    information, and adds three columns to the data frame, each\n",
    "    containing the transformed version of Market Cap column to\n",
    "    respective currencies'''\n",
    "    \n",
    "    # Load exchange rate CSV file\n",
    "    exchange_df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Convert exchange rates DataFrame to dictionary\n",
    "    exchange_rate = exchange_df.set_index('Currency')['Rate'].to_dict()\n",
    "    new_columns = [\"MC_GBP_Billion\", \"MC_EUR_Billion\", \"MC_INR_Billion\"]\n",
    "\n",
    "# Add them to the DataFrame with default values as None\n",
    "    for col in new_columns:\n",
    "        df[col] = None\n",
    "    df['MC_USD_Billion']= df['MC_USD_Billion'].astype(float)\n",
    "    df['MC_GBP_Billion'] = [np.round(x*exchange_rate['GBP'],2) for x in df['MC_USD_Billion']]\n",
    "    df['MC_EUR_Billion'] = [np.round(x*exchange_rate['EUR'],2) for x in df['MC_USD_Billion']]\n",
    "    df['MC_INR_Billion'] = [np.round(x*exchange_rate['INR'],2) for x in df['MC_USD_Billion']]\n",
    "    return df\n",
    "\n",
    "df=transform(df, csv_path)\n",
    "\n",
    "print(df)\n",
    "\n",
    "log_progress('Data transformation complete. Initiating Loading process')\n",
    "\n",
    "print(df.loc[4, 'MC_EUR_Billion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f017b3",
   "metadata": {},
   "source": [
    "**Task 4: Loading to CSV**\n",
    "\n",
    "Below is the function to load the transformed data frame to a CSV file, like load_to_csv(), in the output path \n",
    "\n",
    "Make the relevant log entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0891b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_csv(df, output_path):\n",
    "    ''' This function saves the final data frame as a CSV file in\n",
    "    the provided path. Function returns nothing.'''\n",
    "    df.to_csv(output_path)\n",
    "\n",
    "load_to_csv(df, output_path)\n",
    "log_progress('Data saved to CSV file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79454aa3",
   "metadata": {},
   "source": [
    "**Task 5: Loading to Database**\n",
    "\n",
    "Write the function to load the transformed data frame to an SQL database, like, load_to_db(). Use the database and table names as mentioned in the project scenario.\n",
    "\n",
    "Before calling this function, initiate the connection to the SQL database server with the name Banks.db. Pass this connection object, along with the required table name Largest_banks and the transformed data frame, to the load_to_db() function in the function call.\n",
    "\n",
    "Make the relevant log entry.\n",
    "\n",
    "Upon successful function call, you will have loaded the contents of the table with the required data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9044029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into Largest_banks in SQL Server.\n"
     ]
    }
   ],
   "source": [
    "def load_to_db(df, server_name, db_name, table_name):\n",
    "    '''This function saves the final dataframe to a SQL Server table.'''\n",
    "    \n",
    "    # Establish connection to local SQL Server\n",
    "    conn = pyodbc.connect(f'DRIVER=SQL Server;SERVER={server_name};DATABASE={db_name};Trusted_Connection=yes;')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Drop table if it exists\n",
    "    drop_table_query = f\"IF OBJECT_ID('{table_name}', 'U') IS NOT NULL DROP TABLE {table_name};\"\n",
    "    cursor.execute(drop_table_query)\n",
    "    conn.commit()\n",
    "\n",
    "    \n",
    "    # Generate column definitions with correct data types\n",
    "    sql_types = {\n",
    "        'int64': 'INT',\n",
    "        'float64': 'FLOAT',\n",
    "        'object': 'NVARCHAR(255)'\n",
    "    }\n",
    "    \n",
    "    column_defs = ', '.join([f'[{col}] {sql_types[str(df[col].dtype)]}' for col in df.columns])\n",
    "    \n",
    "    # Create table if not exists\n",
    "    create_table_query = f\"\"\"\n",
    "    IF NOT EXISTS (SELECT * FROM sys.tables WHERE name = '{table_name}')\n",
    "    CREATE TABLE {table_name} ({column_defs})\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "\n",
    "    # Insert data\n",
    "    placeholders = ', '.join(['?' for _ in df.columns])\n",
    "    insert_query = f\"INSERT INTO {table_name} VALUES ({placeholders})\"\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(f\"Data loaded into {table_name} in SQL Server.\")\n",
    "\n",
    "\n",
    "\n",
    "log_progress('SQL Connection initiated.')\n",
    "\n",
    "# Load DataFrame into SQL Server\n",
    "load_to_db(df, server_name, db_name, table_name)\n",
    "\n",
    "log_progress('Data loaded to Database as table. Running the query.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb24f4",
   "metadata": {},
   "source": [
    "**Task 6: Function to Run queries on Database**\n",
    "\n",
    "Below is the function run_queries() that accepts the query statement, and the SQL Server Connection object, and generates the output of the query. The query statement should be printed along with the query output.\n",
    "\n",
    "Execute 3 function calls using the queries as mentioned below.\n",
    "\n",
    "1. Print the contents of the entire table\n",
    "\n",
    "Query statement:   SELECT * FROM Largest_banks\n",
    "\n",
    "2. Print the average market capitalization of all the banks in Billion USD.\n",
    "\n",
    "Query statement:   SELECT AVG(MC_GBP_Billion) FROM Largest_banks\n",
    "\n",
    "3. Print only the names of the top 5 banks\n",
    "\n",
    "Query statement:   SELECT TOP 5 Name FROM Largest_banks\n",
    "\n",
    "Make the relevant log entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab45bf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM Largest_banks\n",
      "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
      "0                           JPMorgan Chase          432.92          346.34   \n",
      "1                          Bank of America          231.52          185.22   \n",
      "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
      "3               Agricultural Bank of China          160.68          128.54   \n",
      "4                                HDFC Bank          157.91          126.33   \n",
      "5                              Wells Fargo          155.87          124.70   \n",
      "6                        HSBC Holdings PLC          148.90          119.12   \n",
      "7                           Morgan Stanley          140.83          112.66   \n",
      "8                  China Construction Bank          139.82          111.86   \n",
      "9                            Bank of China          136.81          109.45   \n",
      "\n",
      "   MC_EUR_Billion  MC_INR_Billion  \n",
      "0          402.62        35910.71  \n",
      "1          215.31        19204.58  \n",
      "2          180.94        16138.75  \n",
      "3          149.43        13328.41  \n",
      "4          146.86        13098.63  \n",
      "5          144.96        12929.42  \n",
      "6          138.48        12351.26  \n",
      "7          130.97        11681.85  \n",
      "8          130.03        11598.07  \n",
      "9          127.23        11348.39  \n",
      "SELECT AVG(MC_GBP_Billion) FROM Largest_banks\n",
      "          \n",
      "0  151.987\n",
      "SELECT TOP 5 Name FROM Largest_banks\n",
      "                                      Name\n",
      "0                           JPMorgan Chase\n",
      "1                          Bank of America\n",
      "2  Industrial and Commercial Bank of China\n",
      "3               Agricultural Bank of China\n",
      "4                                HDFC Bank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jyoth\\AppData\\Local\\Temp\\ipykernel_15612\\2591526257.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  query_output = pd.read_sql(query_statement, conn)\n",
      "C:\\Users\\jyoth\\AppData\\Local\\Temp\\ipykernel_15612\\2591526257.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  query_output = pd.read_sql(query_statement, conn)\n",
      "C:\\Users\\jyoth\\AppData\\Local\\Temp\\ipykernel_15612\\2591526257.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  query_output = pd.read_sql(query_statement, conn)\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect(f'DRIVER=SQL Server;SERVER={server_name};DATABASE={db_name};Trusted_Connection=yes;')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def run_query(query_statement, conn):\n",
    "    print(query_statement)\n",
    "    query_output = pd.read_sql(query_statement, conn)\n",
    "    print(query_output)\n",
    "\n",
    "query_statement = f\"SELECT * FROM Largest_banks\"\n",
    "run_query(query_statement, conn)\n",
    "\n",
    "query_statement = f\"SELECT AVG(MC_GBP_Billion) FROM Largest_banks\"\n",
    "run_query(query_statement, conn)\n",
    "\n",
    "query_statement = f\"SELECT TOP 5 Name FROM Largest_banks\"\n",
    "run_query(query_statement, conn)\n",
    "\n",
    "log_progress('Process Complete.')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "log_progress('Server Connection closed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa9b5e",
   "metadata": {},
   "source": [
    "**Task 7: Verify log entries**\n",
    "\n",
    "After updating all the log_progress() function calls, you have to run the code for a final execution. However, you will first have to remove the code_log.txt file, that would have been created and updated throughout the multiple executions of the code \n",
    "and run the final execution. Upon successful completion of execution, open the code_log.txt file. Now you should see all the relevant entries made in the text file in relation to the stages of code execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ad99e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
